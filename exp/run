#!/usr/bin/env bash
usage='run [-hndifr] [-c|--cores]=CORES [-ts|--tstart]=START [-te|--tend]=END [OPTIONS...] MODEL_TYPE EXPERIMENT_DIR'
doc="This script runs the GFDL dry core model in blocks of N days, and processes
the parallel output NetCDF files with './process' before merging them. This means
pressure level interpolation, heat flux calcualtion, etc. are done in parallel
just like the model integration, which can save huge amounts of time. For a
description of namelist/diagnostic table parameters, see README.md.

Usage

  $usage

Positional arguments

  DIR  The directory in which model will be run. Copies 'input.nml' and
       'diag_table' files to the top level.

Run mode spec

  This is the experiment mode. Passed with the flag [-m|--mode]=MODE

  * 0 is control run, the default.
  * 1 is radiation off spindown.
  * 2 is radiation off but surface on spindown.
  * 3 is everything off (radiation, surface, and friction) spindown.
  * 4 for friction off spindown.

Optional arguments

  -h|--help               Print this message.
  -i|--init               Exit after saving the 'constants.nc' data.
  -r|--resume             Resume model run from last block in the experiment directory. Use this to continue interrupted runs.
  -rs|--restart           Exit if the experiment ran successfully through time 'tend'. Use this to restart crashed runs with smaller timestep.
  -rt|--restart-tdt       Exit if we have generated tdt files through time 'tend'. Use this when generating data for locked runs.
  [-c|--cores]=*          The number of cores to parallelize over.
  [-d|--days]=*           The number of days in each experiment subfolder.
  [-dt|--timestep]=*      The timestep in seconds.
  [-ts|--tstart]=*        The initial day. Can use this to continue from another run.
  [-te|--tend]=*          The final day.
  [-rd|--restart]=*       The initial restart directory.
  [-tsp|--tspindown]=*    Comma-separated list of initial spindown days.
  [-p|--process]=*        Path to the processing script. Defaults to the includes './process' file.
  [-pi|--process-init]=*  Path to processing script for initial 'constants' run.
  [-nml|--namelist]=*     Use this namelist for the experiment. Defaults to the one in the 'exp' folder.
  [-diag|--diagtable]=*   Use this diagnostic table for the experiment. Defaults to the one in the 'exp' folder.
  [-field|--fieldtable]=* Use this field table for the experiment. Defaults to the one in the 'exp' folder.
  [-topo|--topography]=*  Use this topography data for the experiment. Defaults to no input topography. Your namelist must have topography_option='input'
  [-tdt|--heating]=*      Use this heating data for the experiment. Defaults to no input heating. Your namelist must have locked_heating=.true.
"
# Initial stuff
sdir=$(readlink -f ${0})
sdir=${sdir%/*}
source $sdir/header.sh
shopt -u nullglob
ulimit -s unlimited
which realpath &>/dev/null || raise "This script requires the 'realpath' command. 'realpath' not found."
export PATH="/usr/lib64/mpich/bin:$PATH" # add mpi executable to path
export LD_LIBRARY_PATH="/usr/lib64/mpich/lib:/usr/local/lib:$LD_LIBRARY_PATH"

# Parse input flags
# First declare some defaults
mode=0
cores=8
init=false
resume=false
irestart=false
jrestart=false
tend=0
tstart=0 # defaults
ktstart=0
ktend=0
nml=$sdir/input.nml
diag=$sdir/diag_table
field=$sdir/field_table
pinline=$sdir/process
while [ $# -gt 0 ]; do # echo "Flag: $1"
  case "$1" in
    # Flags
    -h|--help) echo "$doc" && exit 0 ;;
    -i|--init) init=true ;; # *only* save forcing scheme data to file?
    -r|--resume) resume=true ;; # use this to *autodetect* last day of existing run, continue from there
    -rs|--restart) irestart=true ;;
    -rt|--restart-tdt) jrestart=true ;;
    -d=*|--days=*) rdays=${1#*=} ;; # number of days
    -m=*|--mode=*) mode=${1#*=} ;; # 0 is control, 1 is spindown, 2...
    -c=*|--cores=*) cores=${1#*=} ;;
    -dt=*|--timestep) timestep=${1#*=} ;;
    -ts=*|--tstart=*) tstart=${1#*=} ;; # use this to continue from *particular* day of existing run
    -te=*|--tend=*) tend=${1#*=} ;; # ending day
    -rd=*|--restart=*) rinit=${1#*=} ;; # manual override restart directory
    -kts=*|--ktstart=*) ktstart=${1#*=} ;;
    -kte=*|--ktend=*) ktend=${1#*=} ;;
    -tsp=*|--tspindown=*) tspindown=($(echo ${1#*=} | tr ',' ' ')) ;;
    -p=*|--process=*) pinline=${1#*=} ;; # name of the process script
    -pi=*|--process-init=*) pinit=${1#*=} ;; # name of the process script
    -nml=*|--namelist=*) nml=${1#*=} ;;
    -diag=*|--diagtable=*) diag=${1#*=} ;;
    -field=*|--fieldtable=*) field=${1#*=} ;;
    -topo=*|--topography=*) topo=${1#*=} ;;
    -tdt=*|--heating=*) tdt=${1#*=} ;;
    -*) gpflags+="$1 " ;; # send all extra flags to process function
    # Positional args
    *)
    if [ -z "$model" ]; then
      model="$1"
    elif [ -z "$expdir" ]; then
      expdir="$1"
    else
      raise "This script requires exactly two positional arguments."
    fi ;;
  esac
  shift
done
[ -n "$gpflags" ] && echo "Passing these flags to processing script: $gpflags"
# Errors and messages
# export MPI_SHEPHERD=true # see: https://www2.cisl.ucar.edu/sites/default/files/intro_to_hpc.pdf
# when mpiexec_mpt used, MPI_SHEPHERD required, but this failed for me
run=mpirun # for running in parallel
which $run &>/dev/null || raise "$run not found in \$PATH."
! $init && [ $tend -eq 0 ] && raise "You must pass an end time"
[ -z "$model" ] && raise "You must declare the model type name."
[ -z "$expdir" ] && raise "You must declare the experiment directory."
[ -x "${sdir}/${model}.x" ] || raise "Invalid model \"${model}\". The executable \"${sdir}/${model}.x\" is missing."
model=$sdir/${model}.x
# Default files and scripts
nml=$(realpath $nml)
diag=$(realpath $diag)
field=$(realpath $field)
pinline=$(realpath $pinline)
[ -r "$nml" ] || raise "Namelist file \"$nml\" not found or is not readable."
[ -r "$diag" ] || raise "Diagnostic table file \"$diag\" not found or is not readable."
[ -r "$field" ] || raise "Field table file \"$field\" not found or is not readable."
[ -x "$pinline" ] || raise "Processing script \"$pinline\" not found or is not executable."
if [ -n "$pinit" ]; then
  pinit=$(realpath $pinit)
  [ -x "$pinit" ] || raise "Initial processing script \"$pinit\" not found or is not executable."
fi
if [ -n "$topo" ]; then
  topo=$(realpath $topo)
  [ -r "$topo" ] || raise "Topography file \"$topo\" not found or is not readable."
fi
if [ -n "$tdt" ]; then
  tdt=$(realpath $tdt)
  [ -r "$tdt" ] || raise "Diabatic heating file \"$tdt\" not found or is not readable."
fi
# Namelist, diag table, field table
# Restart directory
if [ -n "$rinit" ] && ! [[ $rinit =~ d.*-d.* ]]; then
  rinit=($rinit/d*-d*)
  rinit="${rinit[-1]}"
fi

# Make experiment directory
[ -d $expdir ] || mkdir $expdir || raise "Could not create experiment directory \"$expdir\"."
# Copy files
# Ignore error if these are the same file
cp $nml $expdir/input.nml 2>/dev/null
cp $diag $expdir/diag_table 2>/dev/null
cp $field $expdir/field_table 2>/dev/null
[ -n "$tdt" ] && cp $tdt $expdir/heating.data.nc 2>/dev/null
[ -n "$topo" ] && cp $topo $expdir/topography.data.nc 2>/dev/null
# Apply timestep and days if they were passed
[ -n "$rdays" ] && nml_replace $expdir/input.nml days "$rdays"
[ -n "$timestep" ] && nml_replace $expdir/input.nml dt_atmos "$timestep"
rdays=$(nml_parse $expdir/input.nml days) # number of days in each block
[ "$rdays" -eq 0 ] && raise "Namelist file \"$expdir/input.nml\" has run length days=0. You can change this by providing your own namelist with -nml=file or using the flag -d=days."
dt=$(nml_parse $expdir/input.nml dt_atmos)
[ "$dt" -eq 0 ] && raise "Namelist file \"$expdir/input.nml\" has model timestep dt_atmos=0. You can change this by providing your own namelist with -nml=file or using the flag -dt=timestep."

# Bail out of entire script in some situations
if $irestart; then
  # Restart failed run from *beginning*, suitable for when run is unstable
  # and we are trying a smaller timestep
  edays=($expdir/d????-d????)
  edays=(${edays[@]##*d})
  if [ ${edays[-1]} == $tend ]; then
    echo "Model run already completed."
    exit 0
  fi
  echo "Restarting experiment."
fi
if $jrestart; then
  # Check that mean NetCDF files exist all the way out, bail if they
  # do. Use this to generate tdt files for locked runs.
  edays=($expdir/netcdf/mean_tdt.d????-d????.nc)
  edays=(${edays[@]##*d})
  edays=(${edays[@]%.nc})
  if [ ${edays[-1]} == $tend ]; then
    echo "Already generated tdt files."
    exit 0
  fi
  echo "Restarting experiment."
fi

################################################################################
# Function for restarting model. Puts correct files in correct place so
# model can read them and continue iteration from a previous state.
################################################################################
# Take one argument: directory where restart files exist
copy_restart() {
  # Move restart files
  local cday rdir usage
  usage="copy_restart CURRENT_DAY RESTART_DIR"
  cday=$1
  rdir=$2 # the restart direcotry
  if ! [ -d "$rdir" ] || ! [ -d "$rdir/RESTART" ] \
    || [ -z "$(ls $rdir/RESTART/*.nc 2>/dev/null)" ] \
    || ! [ -r "$rdir/RESTART/atmos_model.res" ]; then
    raise "Restart directory $rdir/RESTART does not exist, or is missing atmos_model.res and/or the restart NetCDF files."
  fi
  echo "Moving restart files from ${rdir##*/}/RESTART to ${PWD##*/}/INPUT..."
  for file in $rdir/RESTART/*; do
    cp $file INPUT/${file##*/}
  done
  # Enforce starting time
  # WARNING: After day 10000, 'days' field runs into 'month' field in atmos_model.res
  # which causes weird error with 1 timestep in output NetCDF files and data corruption
  # Editing namelist does not work because current time overwritten by the
  # INPUT/atmos_model.res file. Need to edit the latter.
  if [ $cday -eq 0 ]; then
    sed -i 's/ \+/ /g;s/[0-9]*[1-9][0-9]*/0/g' INPUT/atmos_model.res
    cp $rdir/input.nml ../restart.nml # store the restart namelist in root directory for experiment
    echo ${rdir} >../restart.log
  fi
}

################################################################################
# Function for setting up a directory for the model executable to
# run inside.
################################################################################
dir_setup() {
  # Set up working directory, and move there
  local cday wdir usage
  usage="dir_setup CURRENT_DAY CURRENT_DIR"
  cday="$1"
  wdir="$2" # where to move files
  if [ ${wdir##*/} == "constants" ]; then
    rm -rf $wdir 2>/dev/null
  elif ! [ -d $wdir ]; then
    # Resume run here
    echo "Setting up working directory ${wdir##*/}..."
    resume=false
  elif $resume; then
    # Resume interrupted run
    # NOTE: This checks for contents of netcdf folder
    # if compgen -G "$wdir/../netcdf/*${wdir##*/}.nc" &>/dev/null; then
    # if compgen -G "$wdir/../netcdf/*tdt*${wdir##*/}.nc" &>/dev/null; then
    #   && compgen -G "$wdir/../netcdf/*tdt*${wdir##*/}.nc" &>/dev/null; then
    # if compgen -G "$wdir/RESTART/*.nc" &>/dev/null \
    #   && compgen -G "$wdir/../netcdf/*${wdir##*/}.nc" &>/dev/null; then
    if compgen -G "$wdir/../netcdf/*${wdir##*/}.nc" &>/dev/null; then
      echo "NetCDF files already exist for block ${wdir##*/}. Cancelling..."
      return 1 # breaks out of if statement
    fi
    # Otherwise, resume run and delete 'unfinished' contents
    echo "No NetCDF files found for block ${wdir##*/}. Resuming..."
    resume=false
    rm -rf $wdir
  else
    # Overwrite
    echo "Working directory ${wdir##*/} already exists. Deleting..."
    rm -rf $wdir
  fi

  # Make directory and move stuff over
  mkdir $wdir
  [ $? -ne 0 ] && raise "Failed to create working directory \"$wdir\"." && return 1
  cd $wdir
  cp $model . # move executable inside (declared at top of file)
  mkdir RESTART # model spits out stuff here, can be accepted as input to new iteration
  mkdir INPUT   # model reads from this
  mkdir DATA    # for realistic Earth topography, see topography.html
  touch field_table # just put empty file, if want no tracers

  # Copy existing namelist file over
  # For shutdown experiments, can edit on the fly to turn off
  # radiation, et cetera, but this is starting point
  for ifile in input.nml diag_table field_table; do
    cp $expdir/$ifile ./
  done

  # Input files
  heat=$(nml_parse input.nml locked_heating)
  topo=$(nml_parse input.nml topography_option) # use helper function
  if [ "$topo" == "input" ]; then
    [ -r $expdir/topography.data.nc ] || raise "Topography file \"$expdir/topography.data.nc\" not found."
    cp $expdir/topography.data.nc INPUT/
  fi
  if [ "$heat" == ".true." ]; then
    [ -r $expdir/heating.data.nc ] || raise "Heating file \"$expdir/heating.data.nc\" not found."
    cp $expdir/heating.data.nc INPUT/
  fi

  # Namelist changes for spindown runs
  if [ $mode -gt 0 ]; then
    case $mode in   # determine spindown type
      1) nml_replace input.nml ktrop 0 kbl 0 kstrat 0 kmeso 0 ;; # turn off all thermal damping
      2) nml_replace input.nml ktrop 0 kstrat 0 kmeso 0 ;; # turn off damping except in boundary layer
      3) nml_replace input.nml ktrop 0 kfric 0 kbl 0 kstrat 0 kmeso 0 ;; # turn off all damping
      4) nml_replace input.nml kfric 0 ;; # turn off friction
      *) raise "Unknown experiment identifier \"$mode\"." ;;
    esac
    nml_print
  fi
  return 0
}

################################################################################
# Function for running the next model step and applying post-processing to
# the resulting NetCDF files.
################################################################################
run_model() {
  # Run model in parallel
  local usage cday ncores process
  usage="run_model CURRENT_DAY NCORES PROCESS_SCRIPT"
  cday=$1 # current day
  ncores=$2 # number of processors
  process=$3
  t1=$(date +%s)
  echo "Running model..."
  $run -np $ncores ./${model##*/} &>model.log
  grep -E 'EXIT CODE: [1-9]|FATAL from PE|WARNING from PE' model.log &>/dev/null && \
    raise "Bad exit status from model run step. Check $(pwd)/model.log"
  tmodel=$(cat model.log | grep "Total runtime*" | xargs | cut -d " " -f 5)
  [ -z "$tmodel" ] && raise "Logfile model.log not found or is empty."
  echo "Model time: ${tmodel%.*}s." # is just max of the two

  # Remove some files
  [ -d INPUT ] && [ $cday -gt 0 ] && rm -rf INPUT # remove input *if* this is not start of new run; in that case we want to keep input so know what's going on
  [ -r logfile.0000.out ] && mv logfile.0000.out init.log # contains init info
  rm ${model##*/} # remove executable, because takes up space

  # Process new data, and remove old data
  # Previously we set processor affinities, but didn't help much
  if [ -n "$process" ]; then
    echo "Calling processing script with flags: $(echo $pflags $gpflags | xargs)"
    $process $pflags $gpflags &>process.log
    stat=$?
    [ $stat -ne 0 ] && raise "Exit status $stat from processing NetCDF files. Check $(pwd)/process.log"
    tprocess=$(tail -1 process.log | sed 's/[^0-9]*//g')
    echo "Process time: ${tprocess%.*}s."
  fi
}

################################################################################
# Run model for a second to get the *unchanging* params, i.e. zsurf, teq,
# kdamp, kfric, and ksponge.
################################################################################
# Set up directory
[ -d $expdir/constants ] || mkdir $expdir/constants
dir_setup 0 $expdir/constants
nml_replace $expdir/constants/input.nml dt_atmos 1 days 0 hours 0 minutes 0 seconds 1
cat >$expdir/constants/diag_table <<EOF
"Constant and initial state for dry core experiments"
0 0 0 0 0 0
# Filename
"constants", 1, "seconds", 1, "days", "time",
# Parameters
"dynamics", "ps",         "ps",         "constants", "all", .false., "none", 2,
"dynamics", "slp",        "slp",        "constants", "all", .false., "none", 2,
"dynamics", "zsurf",      "zsurf",      "constants", "all", .false., "none", 2,
"dynamics", "bk",         "hybi",       "constants", "all", .false., "none", 2,
"dynamics", "pk",         "hyai",       "constants", "all", .false., "none", 2,
"forcing",  "teq",        "teq",        "constants", "all", .false., "none", 2,
"forcing",  "ndamp",      "ndamp",      "constants", "all", .false., "none", 2,
"forcing",  "rdamp",      "rdamp",      "constants", "all", .false., "none", 2,
"forcing",  "sdamp",      "sdamp",      "constants", "all", .false., "none", 2,
"forcing",  "heating",    "heating",    "constants", "all", .false., "none", 2,
"forcing",  "forcing",    "forcing",    "constants", "all", .false., "none", 2,
"forcing",  "ndamp_mean", "ndamp_mean", "constants", "all", .false., "none", 2,
"forcing",  "ndamp_anom", "ndamp_anom", "constants", "all", .false., "none", 2,
"forcing",  "rdamp_mean", "rdamp_mean", "constants", "all", .false., "none", 2,
"forcing",  "rdamp_anom", "rdamp_anom", "constants", "all", .false., "none", 2,
EOF
# Run model
echo "Getting forcing data..."
run_model 0 1 $pinit || raise "Forcing run failed. Check log files in the forcing folder."
$init && exit 0

##############################################################################
# Control run
# Run the model in blocks of $rdays days for control, then optionally choose
# starting points from control for spin-down ensemble experiments
##############################################################################
estatus=0
if [ $mode -eq 0 ]; then
  # Prepare for the loop
  echo "Running control experiment from day $tstart to day $tend on $cores cores, restart every $rdays days."
  coldstart=true # assume cold start by default
  t0=$(date +%s) # start time
  pday=0 # only time when we do minus days
  cday=0
  nday=$rdays
  while [ $nday -le $tend ]; do
    # Message and reset timer/flags
    if [ $cday -lt $tstart ]; then
      [ -n "$rinit" ] && echo "Ignoring restart directory ${rinit}."
      unset rinit # important! for 'resume' experiments, generally just want to use rinit as cold start alternative
      pday=$cday # previous day
      cday=$((pday + rdays))
      nday=$((cday + rdays))
      continue
    fi
    echo "Running from day $cday to day $nday."
    time=$(date +%s)
    # Run the model and combine output
    # Optionally use the end of other control runs to reduce spinup time
    rdir=$expdir/d$(printf "%04d" $pday)-d$(printf "%04d" $cday)
    cdir=$expdir/d$(printf "%04d" $cday)-d$(printf "%04d" $nday)
    if [ -n "$rinit" ]; then
      coldstart=false
      [ -d $rinit ] || raise "Override restart directory \"$rinit\" does not exist."
      echo "Using restart files from \"$rinit\"."
      rdir="$rinit" # use specific day sequence
      unset rinit # only ever use this on first 'day' of a new experiment; for subsequent days, continue from earlier day block
    fi
    unset pflags
    if [ $cday -lt $ktstart ] || [ $cday -gt $ktend ]; then
      pflags=" -k" && echo "Full resolution netcdf files will be kept."
    fi
    dir_setup $cday $cdir # sets up working directory, cd into it
    if [ $? -eq 0 ]; then # setup returns 1 if directory is present and 'resume' option is set
      if ! $coldstart || [ $cday -gt 0 ]; then
        copy_restart $cday $rdir # put files into RESTART directory
      else
        echo "Cold start."
      fi
      run_model $cday $cores $pinline
    fi
    [ $rdays -eq 0 ] && break # exit for initial condition experiment
    # Step things forward, for next iteration
    pday=$cday
    cday=$((pday + rdays))
    nday=$((cday + rdays))
  done
  # Last file
  if [ -r process.log ]; then
    tprocess=$(tail -1 process.log | sed 's/[^0-9]*//g')
    echo "Final process time: ${tprocess%.*}s."
  fi
  # Message
  echo "The control run completed successfully in $(($(date +%s) - t0)) seconds!"
  echo "Timestamp: $(date)."

##############################################################################
# Spindown runs
# User must specify which namelist params are getting abruptly changed.
##############################################################################
else
  # Prepare for the loop
  [ -z $tspindown ] && raise "Must declare starting times for spindown experiments."
  echo "Running spindown experiment $mode from days ${tspindown[@]} for $tend days, restart every $rdays days."
  t0=$(date +%s)
  # Iterate through starting days
  for eday in "${tspindown[@]}"; do
    cday=0 # current day relative to start of equilibrium
    nday=$rdays # next day, relative to start
    prefix=$expdir/d$(printf "%04d" $eday) # for successive spindown runs
    fstart=$expdir/d$(printf "%04d" $((eday - rdays)))-d$(printf "%04d" $eday) # for restart files from control
    ts=$(date +%s) # record time
    echo "Starting radiation-off spindown run from day $eday for $tend days."
    while [ $nday -le $tend ]; do
      # Skip this time (optionally)
      if [ $cday -lt $tstart ]; then
        echo "Skipping day $cday."
        pday=$cday # previous day
        cday=$((pday + rdays))
        nday=$((cday + rdays))
        continue
      fi
      # Get directories
      cdir=$prefix-spindown$mode-d$(printf "%04d" $cday)-d$(printf "%04d" $nday)
      [ $cday -eq 0 ] && rdir=$fstart || \
        rdir=$prefix-spindown$mode-d$(printf "%04d" $pday)-d$(printf "%04d" $cday)
      # Run the model and combine output
      unset pflags
      if [ $cday -lt $ktstart ] || [ $cday -gt $ktend ]; then
        pflags=" -k" && echo "Full resolution netcdf files will be kept."
      fi
      dir_setup $cday $cdir # sets up working directory, cd into it
      if [ $? == 0 ]; then # returns 1 if we were requested not to overwrite old directories
        copy_restart $cday $rdir
        run_model $cday $cores $pinline
      fi
      # Step things forward, for next iteration
      pday=$cday # previous day
      cday=$((pday + rdays))
      nday=$((cday + rdays))
    done
    echo "Spindown from $eday completed successfully in $(($(date +%s) - ts)) seconds!"
    echo "Timestamp: $(date)."
  done
  if [ -r process.log ]; then
    tprocess=$(tail -1 process.log | sed 's/[^0-9]*//g')
    echo "Final process time: ${tprocess%.*}s."
  fi
  echo "The spindown runs completed successfuly in $(($(date +%s) - t0)) seconds!"
  echo "Timestamp: $(date)."
fi
