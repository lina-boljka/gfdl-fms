#!/bin/bash
usage='drycore_run [OPTION...] DIR'
doc="This script runs GFDL dry core model successively in folders named dXXXX-dYYYY
within the directory DIR, combines the multiple netcdf files produced in parallel,
and moves them to a folder named 'netcdf'.

Usage

  $usage

Positional arguments

  DIR  The directory in which model will be run.

Optional arguments

  -h|--help          Print this message.
  -n|--new           Exit if experiment folder already exists.
  -r|--resume        Exit if particular run block already exists. Use this to continue interrupted runs.
  [-c|--cores]=*     The number of cores to parallelize over.
  [-ts|--tstart]=*   The initial day. Can use this to continue from another run.
  [-te|--tend]=*     The final day.
  [-rd|--restart]=*  The initial restart directory.
"
# Initial stuff
cwd=$(pwd)
shopt -u nullglob   # google this
ulimit -s unlimited # set max open files
mpibin=/usr/lib64/mpich/bin
export PATH="$mpibin:$PATH" # add mpi executable to path
# Error
raise() {
  echo "Usage: $usage" 1>&2
  echo "Error: $@" 1>&2
  exit 1
}
# Function for reading values set in namelist
nml_parse() {
  [ ! -r "$cwd/input.nml" ]  && raise "input.nml file not found."
  cat input.nml | sed 's/!.*//g' | grep "$1" | cut -d= -f2 | tr -d "\t ,'\""
}

################################################################################
# Check input
################################################################################
# Declare defaults and parse input
cores=4
tstart=0
newexp=false
resume=false
days=$(nml_parse days) # number of days in each block
while [ $# -gt 0 ]; do # echo "Flag: $1"
  case "$1" in
    -h|--help) echo "$doc" && exit 0  ;;
    -n|--new)          newexp=true    ;;
    -r|--resume)       resume=true    ;;
    -c=*|--cores=*)    cores=${1#*=}  ;;
    -ts=*|--start=*)   tstart=${1#*=} ;;
    -te=*|--end=*)     tend=${1#*=}   ;;
    -rd=*|--restart=*) rinit=${1#*=}  ;;
    -*) raise "Unknown flag \"$1\"." ;;
    *)  [ -n "$expdir" ] && raise "More than one experiment directory specified."
      expdir="$1" ;;
  esac; shift # shift by at least one
done
[ -z $expdir ] && raise "You must declare the experiment directory."
[ -z $tend ] && raise "You must declare the end day."
# Check that exe is available
# You should copy the exe from whichever compile script
fms=$cwd/fms.x                   # model executable
mppnccombine=$cwd/mppnccombine.x # netcdf combine executable
! [ -x $fms ]  && raise "The executable $fms is missing."
! [ -x $mppnccombine ] && raise "The executable $mppnccombine is missing."
# Exit from script if directory already exists
$newexp && [ -d $expdir ] && raise "Working directory already exists."
if ! [ -d $expdir ]; then
  mkdir $expdir # make directory
  [ $? -ne 0 ] && raise "Could not create experiment directory \"$expdir\"."
fi

################################################################################
# Helper functions for model runs
################################################################################
# Set up input files for model executable to read
# by matching indentation, which can be done with <<-DELIM; literal tab chars ignored
# https://unix.stackexchange.com/questions/76481/cant-indent-heredoc-to-match-nestings-indent
################################################################################
# Takes two arguments: 1) the working directory, and 2) the iteration mode
dir_setup() {
  # Set up working directory, and move there
  # Action depends on settings
  wdir="$1" # where to move files
  [ $# -ne 1 ] && raise "dir_setup() functions requires exactly 1 argument."
  if ! [ -d $wdir ]; then
    # Directory does not exist, just create if from scratch
    resume=false
    echo "Setting up working directory ${wdir##*/}..."
  elif $resume; then
    # Directory exists
    # Check if this directory contains finished results
    if ! [ -z "$(\ls $wdir/RESTART 2>/dev/null)" ]; then # need to check RESTART folder is non-empty
      echo "Working directory ${wdir##*/} contains completed integration. Cancelling..."
      return 1
    fi
    # If not, we are "resuming" the experiment run at this timestep
    resume=false
    echo "Working directory ${wdir##*/} contains unfinished integration. Starting over..."
    rm -r $wdir
  else
    # Delete the folder, we don't care what's in it
    echo "Working directory ${wdir##*/} already exists. Deleting..."
    rm -r $wdir
  fi
  # Make directory and move stuff over
  mkdir $wdir
  [ $? -ne 0 ] && raise "Could not create working directory \"$wdir\"."
  cd $wdir
  cp $fms ./fms.x   # move executable inside (declared at top of file)
  mkdir RESTART     # model spits out stuff here, can be accepted as input to new iteration
  mkdir INPUT       # model reads from this
  touch field_table # just put empty file, if want no tracers
  # Copy files over
  ! [ -r "$cwd/input.nml" ]  && raise "input.nml file not found."
  ! [ -r "$cwd/diag_table" ] && raise "diag_table file not found."
  cat $cwd/input.nml | sed 's/!.*//g' | sed 's/[ \t]*$//g' | sed $'/^[ \t]*$/d' >./input.nml
  cp $cwd/diag_table ./
  topo=$(nml_parse topography_option) # use helper function
  if [ "$topo" == "input" ]; then
    ! [ -r $cwd/topography.data.nc ] && raise "Topography file not found"
    cp $cwd/topography.data.nc INPUT
  fi
  return 0
}

################################################################################
# Function for restarting model; put correct files in correct place so 
# fms can read them and continue iteration from a previous state.
################################################################################
# Take one argument: directory where restart files exist
copy_restart() {
  # Move restart files
  local rdir=$1 # the restart direcotry
  [ $# -ne 1 ] && raise "copy_restart() function takes exactly 1 argument."
  if ! [ -d "$rdir" ] || ! [ -d "$rdir/RESTART" ] || [ -z "$(ls $rdir/RESTART/*.nc 2>/dev/null)" ] || ! [ -r "$rdir/RESTART/atmos_model.res" ]; then
    raise "Restart directory $rdir/RESTART does not exist, or is empty."
  fi
  echo "Moving restart files from ${rdir##*/}/RESTART to ${PWD##*/}/INPUT..."
  for file in $rdir/RESTART/*; do
    cp $file INPUT/${file##*/}
  done
}

################################################################################
# Function for running the next model step from a previous step
################################################################################
run_model() {
  local rdir=$1 # the restart direcotry
  [ $# -ne 1 ] && raise "run_model() function takes exactly 1 argument."
  t=$(date +%s)
  echo "Running model..."
  # Use mpirun to run model in parallel (note mpirun must be on path)
  ! which mpirun &>/dev/null && raise "mpirun not found in \$PATH: ${PATH}."
  mpirun -np $cores ./fms.x &>log.model # need ./fms.x, not fms
  # Check that model ran successfully
  # FMS prints to standard output 'EXIT CODE: 1' but doesn't actually set
  # the exit status/mpirun doesn't pass that exit status, which is dumb. So we'll parse the logfile.
  grep 'EXIT CODE: [1-9]' log.model &>/dev/null && raise "Bad exit code from model run step."
  echo "Time for integration: $(($(date +%s) - $t))s."
  # Combine the parallel-output netcdf files with the GFDL-provided 'mppnccombine' tool (stands for massively parallel processing netcdf-combine)
  t=$(date +%s)
  for ncfile in *.nc.0000; do # for each output filename -- e.g. 4xdaily_inst.nc.XXXX, averages.nc.XXXX, etc.
    # Get list of files to combine
    [[ "$ncfile" =~ "*" ]] && raise "No netcdf files found."
    files=(${ncfile%%.*}.nc*) # glob expands into "bash array" of files; the %%.* is a "parameter expansion" (google this)
    # Combine files
    echo "Combining files: ${files[@]} into ${ncfile%%.*}.nc"
    $mppnccombine -r ${ncfile%%.*}.nc ${files[@]} # -r flag says to remove the decomposed .0000 files after they are combined
    [ $? -ne 0 ] && raise "mppnccombine failed."
    mv ${ncfile%%.*}.nc ../netcdf/${ncfile%%.*}.${PWD##*/}.nc # name will be, e.g., 4xdaily_inst.d0000-d0100.nc
  done
  echo "Time for combining files: $(($(date +%s) - $t))s."
  # Initialize directory for output
  ! [ -d ../netcdf ] && mkdir ../netcdf # make directory if doesn't exist
  ncfiles=(*.nc) # each output file
  # Remove some files
  [ -d INPUT ] && [ $cday -gt 0 ] && rm -rf INPUT # remove everything
  [ -r logfile.0000.out ] && mv logfile.0000.out log.init # contains init info
  rm fms.x # remove executable, because it takes up space
}

##############################################################################
# Run the model in blocks of $days days for control
##############################################################################
echo "Running control experiment from day $tstart to day $tend."
coldstart=true # assume cold start by default
origin=$(date +%s) # start time
pday=$(($tstart - $days)) # only time when we do minus days
cday=$tstart
nday=$(($tstart + $days))
while [ $nday -le $tend ]; do
  # Message and reset timer/flags
  echo "Running from day $cday to day $nday."
  time=$(date +%s)
  # Run the model and combine output
  # Optionally use the end of other control runs to reduce spinup time
  rdir=$expdir/d$(printf "%04d" $pday)-d$(printf "%04d" $cday)
  cdir=$expdir/d$(printf "%04d" $cday)-d$(printf "%04d" $nday)
  if ! [ -z $rinit ]; then coldstart=false
    if ! [[ $rinit =~ d.*-d.* ]]; then
      echo "Override: Using final day from \"$rinit\" for restart files."
      rinit=($rinit/d*-d*)
      rdir="${rinit[-1]}" # pick last one; the glob expansion will return a sorted list of names
    else
      echo "Override: Using restart files from \"$rinit\"."
      rdir="$rinit" # use specific day sequence
    fi
    unset rinit # only ever use this on first 'day' of a new experiment; for subsequent days, continue from earlier day block
    ! [ -d $rdir ] && raise "Override restart directory \"$rdir\" does not exist."
  fi
  dir_setup $cdir # sets up working directory, cd into it
  if [ $? -eq 0 ]; then # setup returns 1 if directory is present and 'resume' option is set
    if ! $coldstart || [ $cday -gt 0 ]; then
      copy_restart $rdir # put files into RESTART directory
    else
      echo "Cold start."
    fi
    run_model $rdir # run model
  fi
  # Step things forward, for next iteration
  pday=$cday
  cday=$(($pday + $days))
  nday=$(($cday + $days))
done
echo "The control run completed successfully in $(($(date +%s) - $origin)) seconds!"
echo "Timestamp: $(date)."

